{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2030015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import History \n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0bfd8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Trinity\\Documents\\ANN_project\\dataset-HAR-PUC-Rio.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "eec64969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>how_tall_in_meters</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>z4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-3</td>\n",
       "      <td>92</td>\n",
       "      <td>-63</td>\n",
       "      <td>-23</td>\n",
       "      <td>18</td>\n",
       "      <td>-19</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>-92</td>\n",
       "      <td>-150</td>\n",
       "      <td>-103</td>\n",
       "      <td>-147</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-3</td>\n",
       "      <td>94</td>\n",
       "      <td>-64</td>\n",
       "      <td>-21</td>\n",
       "      <td>18</td>\n",
       "      <td>-18</td>\n",
       "      <td>-14</td>\n",
       "      <td>104</td>\n",
       "      <td>-90</td>\n",
       "      <td>-149</td>\n",
       "      <td>-104</td>\n",
       "      <td>-145</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "      <td>-61</td>\n",
       "      <td>-12</td>\n",
       "      <td>20</td>\n",
       "      <td>-15</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-90</td>\n",
       "      <td>-151</td>\n",
       "      <td>-104</td>\n",
       "      <td>-144</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-2</td>\n",
       "      <td>96</td>\n",
       "      <td>-57</td>\n",
       "      <td>-15</td>\n",
       "      <td>21</td>\n",
       "      <td>-16</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-89</td>\n",
       "      <td>-153</td>\n",
       "      <td>-103</td>\n",
       "      <td>-142</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debora</td>\n",
       "      <td>Woman</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>-61</td>\n",
       "      <td>-13</td>\n",
       "      <td>20</td>\n",
       "      <td>-15</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-89</td>\n",
       "      <td>-153</td>\n",
       "      <td>-104</td>\n",
       "      <td>-143</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user gender  age  how_tall_in_meters  weight  body_mass_index  x1  y1   \n",
       "0  debora  Woman   46                1.62      75             28.6  -3  92  \\\n",
       "1  debora  Woman   46                1.62      75             28.6  -3  94   \n",
       "2  debora  Woman   46                1.62      75             28.6  -1  97   \n",
       "3  debora  Woman   46                1.62      75             28.6  -2  96   \n",
       "4  debora  Woman   46                1.62      75             28.6  -1  96   \n",
       "\n",
       "   z1  x2  y2  z2  x3   y3  z3   x4   y4   z4    Class  \n",
       "0 -63 -23  18 -19   5  104 -92 -150 -103 -147  sitting  \n",
       "1 -64 -21  18 -18 -14  104 -90 -149 -104 -145  sitting  \n",
       "2 -61 -12  20 -15 -13  104 -90 -151 -104 -144  sitting  \n",
       "3 -57 -15  21 -16 -13  104 -89 -153 -103 -142  sitting  \n",
       "4 -61 -13  20 -15 -13  104 -89 -153 -104 -143  sitting  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= pd.read_csv(path, delimiter=\";\", decimal = \",\", low_memory=False) # Read the file\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fda56976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>how_tall_in_meters</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_mass_index</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>z4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-3</td>\n",
       "      <td>92</td>\n",
       "      <td>-63</td>\n",
       "      <td>-23</td>\n",
       "      <td>18</td>\n",
       "      <td>-19</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>-92</td>\n",
       "      <td>-150</td>\n",
       "      <td>-103</td>\n",
       "      <td>-147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-3</td>\n",
       "      <td>94</td>\n",
       "      <td>-64</td>\n",
       "      <td>-21</td>\n",
       "      <td>18</td>\n",
       "      <td>-18</td>\n",
       "      <td>-14</td>\n",
       "      <td>104</td>\n",
       "      <td>-90</td>\n",
       "      <td>-149</td>\n",
       "      <td>-104</td>\n",
       "      <td>-145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "      <td>-61</td>\n",
       "      <td>-12</td>\n",
       "      <td>20</td>\n",
       "      <td>-15</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-90</td>\n",
       "      <td>-151</td>\n",
       "      <td>-104</td>\n",
       "      <td>-144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-2</td>\n",
       "      <td>96</td>\n",
       "      <td>-57</td>\n",
       "      <td>-15</td>\n",
       "      <td>21</td>\n",
       "      <td>-16</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-89</td>\n",
       "      <td>-153</td>\n",
       "      <td>-103</td>\n",
       "      <td>-142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.62</td>\n",
       "      <td>75</td>\n",
       "      <td>28.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>-61</td>\n",
       "      <td>-13</td>\n",
       "      <td>20</td>\n",
       "      <td>-15</td>\n",
       "      <td>-13</td>\n",
       "      <td>104</td>\n",
       "      <td>-89</td>\n",
       "      <td>-153</td>\n",
       "      <td>-104</td>\n",
       "      <td>-143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  gender  age  how_tall_in_meters  weight  body_mass_index  x1  y1  z1   \n",
       "0   0.0     1.0   46                1.62      75             28.6  -3  92 -63  \\\n",
       "1   0.0     1.0   46                1.62      75             28.6  -3  94 -64   \n",
       "2   0.0     1.0   46                1.62      75             28.6  -1  97 -61   \n",
       "3   0.0     1.0   46                1.62      75             28.6  -2  96 -57   \n",
       "4   0.0     1.0   46                1.62      75             28.6  -1  96 -61   \n",
       "\n",
       "   x2  y2  z2  x3   y3  z3   x4   y4   z4  Class  \n",
       "0 -23  18 -19   5  104 -92 -150 -103 -147      0  \n",
       "1 -21  18 -18 -14  104 -90 -149 -104 -145      0  \n",
       "2 -12  20 -15 -13  104 -90 -151 -104 -144      0  \n",
       "3 -15  21 -16 -13  104 -89 -153 -103 -142      0  \n",
       "4 -13  20 -15 -13  104 -89 -153 -104 -143      0  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit(dataset[[\"user\",\"gender\"]])\n",
    "dataset[[\"user\",\"gender\"]] = oe.transform(dataset[[\"user\",\"gender\"]]) # Ordinal encoding of categorical input data\n",
    "\n",
    "le = LabelEncoder()\n",
    "dataset.Class = le.fit_transform(dataset.Class)# Label (integer) encoding of categorical target data\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9015eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training and testing data 5-Fold\n",
    "X = dataset.drop([\"Class\"], axis =1) # Input values\n",
    "Y = dataset[\"Class\"] # Target values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "87eca846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: x-x.mean()) # Mean centering\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X) # Scaling the data to [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f3dad37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle =True) # Each fold has the same percentage of samples for every class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "51f3efbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13226/13251 [============================>.] - ETA: 0s - loss: 1.4946 - accuracy: 0.3228 - mean_squared_error: 5.3653\n",
      "Epoch 1: val_loss improved from inf to 1.45843, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 23s 2ms/step - loss: 1.4946 - accuracy: 0.3229 - mean_squared_error: 5.3657 - val_loss: 1.4584 - val_accuracy: 0.2621 - val_mean_squared_error: 5.3650\n",
      "Epoch 2/30\n",
      "13220/13251 [============================>.] - ETA: 0s - loss: 1.4496 - accuracy: 0.3476 - mean_squared_error: 5.3666\n",
      "Epoch 2: val_loss improved from 1.45843 to 1.44971, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4496 - accuracy: 0.3477 - mean_squared_error: 5.3662 - val_loss: 1.4497 - val_accuracy: 0.3693 - val_mean_squared_error: 5.3662\n",
      "Epoch 3/30\n",
      "13222/13251 [============================>.] - ETA: 0s - loss: 1.4465 - accuracy: 0.3629 - mean_squared_error: 5.3659\n",
      "Epoch 3: val_loss did not improve from 1.44971\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4464 - accuracy: 0.3630 - mean_squared_error: 5.3665 - val_loss: 1.4526 - val_accuracy: 0.2837 - val_mean_squared_error: 5.3674\n",
      "Epoch 4/30\n",
      "13251/13251 [==============================] - ETA: 0s - loss: 1.4433 - accuracy: 0.3680 - mean_squared_error: 5.3670\n",
      "Epoch 4: val_loss improved from 1.44971 to 1.43541, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4433 - accuracy: 0.3680 - mean_squared_error: 5.3670 - val_loss: 1.4354 - val_accuracy: 0.3593 - val_mean_squared_error: 5.3661\n",
      "Epoch 5/30\n",
      "13218/13251 [============================>.] - ETA: 0s - loss: 1.4403 - accuracy: 0.3712 - mean_squared_error: 5.3676\n",
      "Epoch 5: val_loss did not improve from 1.43541\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4404 - accuracy: 0.3713 - mean_squared_error: 5.3675 - val_loss: 1.4380 - val_accuracy: 0.4120 - val_mean_squared_error: 5.3683\n",
      "Epoch 6/30\n",
      "13241/13251 [============================>.] - ETA: 0s - loss: 1.4383 - accuracy: 0.3724 - mean_squared_error: 5.3686\n",
      "Epoch 6: val_loss did not improve from 1.43541\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4383 - accuracy: 0.3723 - mean_squared_error: 5.3681 - val_loss: 1.4359 - val_accuracy: 0.3061 - val_mean_squared_error: 5.3673\n",
      "Epoch 7/30\n",
      "13226/13251 [============================>.] - ETA: 0s - loss: 1.4377 - accuracy: 0.3737 - mean_squared_error: 5.3688\n",
      "Epoch 7: val_loss did not improve from 1.43541\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4377 - accuracy: 0.3738 - mean_squared_error: 5.3686 - val_loss: 1.4431 - val_accuracy: 0.3769 - val_mean_squared_error: 5.3702\n",
      "Epoch 8/30\n",
      "13250/13251 [============================>.] - ETA: 0s - loss: 1.4369 - accuracy: 0.3731 - mean_squared_error: 5.3690\n",
      "Epoch 8: val_loss improved from 1.43541 to 1.42327, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 23s 2ms/step - loss: 1.4369 - accuracy: 0.3731 - mean_squared_error: 5.3689 - val_loss: 1.4233 - val_accuracy: 0.3914 - val_mean_squared_error: 5.3692\n",
      "Epoch 9/30\n",
      "13231/13251 [============================>.] - ETA: 0s - loss: 1.4368 - accuracy: 0.3742 - mean_squared_error: 5.3708\n",
      "Epoch 9: val_loss did not improve from 1.42327\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4368 - accuracy: 0.3742 - mean_squared_error: 5.3694 - val_loss: 1.4732 - val_accuracy: 0.4709 - val_mean_squared_error: 5.3732\n",
      "Epoch 10/30\n",
      "13244/13251 [============================>.] - ETA: 0s - loss: 1.4372 - accuracy: 0.3750 - mean_squared_error: 5.3702\n",
      "Epoch 10: val_loss did not improve from 1.42327\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4371 - accuracy: 0.3750 - mean_squared_error: 5.3698 - val_loss: 1.5517 - val_accuracy: 0.3057 - val_mean_squared_error: 5.3804\n",
      "Epoch 11/30\n",
      "13249/13251 [============================>.] - ETA: 0s - loss: 1.4362 - accuracy: 0.3758 - mean_squared_error: 5.3698\n",
      "Epoch 11: val_loss did not improve from 1.42327\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4362 - accuracy: 0.3758 - mean_squared_error: 5.3699 - val_loss: 1.4313 - val_accuracy: 0.3430 - val_mean_squared_error: 5.3675\n",
      "Epoch 12/30\n",
      "13229/13251 [============================>.] - ETA: 0s - loss: 1.4359 - accuracy: 0.3778 - mean_squared_error: 5.3695\n",
      "Epoch 12: val_loss improved from 1.42327 to 1.42318, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 23s 2ms/step - loss: 1.4359 - accuracy: 0.3778 - mean_squared_error: 5.3701 - val_loss: 1.4232 - val_accuracy: 0.4009 - val_mean_squared_error: 5.3706\n",
      "Epoch 13/30\n",
      "13242/13251 [============================>.] - ETA: 0s - loss: 1.4356 - accuracy: 0.3780 - mean_squared_error: 5.3697\n",
      "Epoch 13: val_loss improved from 1.42318 to 1.41050, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 23s 2ms/step - loss: 1.4356 - accuracy: 0.3780 - mean_squared_error: 5.3702 - val_loss: 1.4105 - val_accuracy: 0.4018 - val_mean_squared_error: 5.3692\n",
      "Epoch 14/30\n",
      "13241/13251 [============================>.] - ETA: 0s - loss: 1.4365 - accuracy: 0.3779 - mean_squared_error: 5.3706\n",
      "Epoch 14: val_loss did not improve from 1.41050\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4365 - accuracy: 0.3779 - mean_squared_error: 5.3704 - val_loss: 1.4489 - val_accuracy: 0.4001 - val_mean_squared_error: 5.3735\n",
      "Epoch 15/30\n",
      "13240/13251 [============================>.] - ETA: 0s - loss: 1.4356 - accuracy: 0.3813 - mean_squared_error: 5.3700\n",
      "Epoch 15: val_loss did not improve from 1.41050\n",
      "13251/13251 [==============================] - 23s 2ms/step - loss: 1.4356 - accuracy: 0.3813 - mean_squared_error: 5.3706 - val_loss: 1.4305 - val_accuracy: 0.4102 - val_mean_squared_error: 5.3690\n",
      "Epoch 16/30\n",
      "13246/13251 [============================>.] - ETA: 0s - loss: 1.4364 - accuracy: 0.3802 - mean_squared_error: 5.3709\n",
      "Epoch 16: val_loss improved from 1.41050 to 1.40859, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 23s 2ms/step - loss: 1.4364 - accuracy: 0.3802 - mean_squared_error: 5.3707 - val_loss: 1.4086 - val_accuracy: 0.3929 - val_mean_squared_error: 5.3688\n",
      "Epoch 17/30\n",
      "13226/13251 [============================>.] - ETA: 0s - loss: 1.4345 - accuracy: 0.3784 - mean_squared_error: 5.3692\n",
      "Epoch 17: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4345 - accuracy: 0.3785 - mean_squared_error: 5.3699 - val_loss: 1.4438 - val_accuracy: 0.3457 - val_mean_squared_error: 5.3684\n",
      "Epoch 18/30\n",
      "13218/13251 [============================>.] - ETA: 0s - loss: 1.4342 - accuracy: 0.3795 - mean_squared_error: 5.3695\n",
      "Epoch 18: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4341 - accuracy: 0.3794 - mean_squared_error: 5.3700 - val_loss: 1.4447 - val_accuracy: 0.2947 - val_mean_squared_error: 5.3715\n",
      "Epoch 19/30\n",
      "13218/13251 [============================>.] - ETA: 0s - loss: 1.4344 - accuracy: 0.3809 - mean_squared_error: 5.3699\n",
      "Epoch 19: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4344 - accuracy: 0.3810 - mean_squared_error: 5.3703 - val_loss: 1.4268 - val_accuracy: 0.3200 - val_mean_squared_error: 5.3707\n",
      "Epoch 20/30\n",
      "13241/13251 [============================>.] - ETA: 0s - loss: 1.4342 - accuracy: 0.3818 - mean_squared_error: 5.3697\n",
      "Epoch 20: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4342 - accuracy: 0.3818 - mean_squared_error: 5.3703 - val_loss: 1.4470 - val_accuracy: 0.3753 - val_mean_squared_error: 5.3679\n",
      "Epoch 21/30\n",
      "13249/13251 [============================>.] - ETA: 0s - loss: 1.4341 - accuracy: 0.3806 - mean_squared_error: 5.3703\n",
      "Epoch 21: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4341 - accuracy: 0.3806 - mean_squared_error: 5.3704 - val_loss: 1.4127 - val_accuracy: 0.3602 - val_mean_squared_error: 5.3674\n",
      "Epoch 22/30\n",
      "13222/13251 [============================>.] - ETA: 0s - loss: 1.4333 - accuracy: 0.3845 - mean_squared_error: 5.3699\n",
      "Epoch 22: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4333 - accuracy: 0.3845 - mean_squared_error: 5.3706 - val_loss: 1.4243 - val_accuracy: 0.4563 - val_mean_squared_error: 5.3672\n",
      "Epoch 23/30\n",
      "13226/13251 [============================>.] - ETA: 0s - loss: 1.4323 - accuracy: 0.3846 - mean_squared_error: 5.3721\n",
      "Epoch 23: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4323 - accuracy: 0.3846 - mean_squared_error: 5.3708 - val_loss: 1.4231 - val_accuracy: 0.4140 - val_mean_squared_error: 5.3718\n",
      "Epoch 24/30\n",
      "13222/13251 [============================>.] - ETA: 0s - loss: 1.4345 - accuracy: 0.3838 - mean_squared_error: 5.3699\n",
      "Epoch 24: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4344 - accuracy: 0.3839 - mean_squared_error: 5.3708 - val_loss: 1.4360 - val_accuracy: 0.4734 - val_mean_squared_error: 5.3734\n",
      "Epoch 25/30\n",
      "13217/13251 [============================>.] - ETA: 0s - loss: 1.4338 - accuracy: 0.3837 - mean_squared_error: 5.3713\n",
      "Epoch 25: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4338 - accuracy: 0.3837 - mean_squared_error: 5.3710 - val_loss: 1.4740 - val_accuracy: 0.3704 - val_mean_squared_error: 5.3682\n",
      "Epoch 26/30\n",
      "13224/13251 [============================>.] - ETA: 0s - loss: 1.4340 - accuracy: 0.3826 - mean_squared_error: 5.3723\n",
      "Epoch 26: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4341 - accuracy: 0.3827 - mean_squared_error: 5.3711 - val_loss: 1.4219 - val_accuracy: 0.4127 - val_mean_squared_error: 5.3694\n",
      "Epoch 27/30\n",
      "13239/13251 [============================>.] - ETA: 0s - loss: 1.4336 - accuracy: 0.3842 - mean_squared_error: 5.3714\n",
      "Epoch 27: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4336 - accuracy: 0.3843 - mean_squared_error: 5.3711 - val_loss: 1.4271 - val_accuracy: 0.4016 - val_mean_squared_error: 5.3704\n",
      "Epoch 28/30\n",
      "13225/13251 [============================>.] - ETA: 0s - loss: 1.4338 - accuracy: 0.3839 - mean_squared_error: 5.3716\n",
      "Epoch 28: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4338 - accuracy: 0.3840 - mean_squared_error: 5.3713 - val_loss: 1.4257 - val_accuracy: 0.3614 - val_mean_squared_error: 5.3698\n",
      "Epoch 29/30\n",
      "13218/13251 [============================>.] - ETA: 0s - loss: 1.4345 - accuracy: 0.3846 - mean_squared_error: 5.3717\n",
      "Epoch 29: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4344 - accuracy: 0.3846 - mean_squared_error: 5.3713 - val_loss: 1.4282 - val_accuracy: 0.4116 - val_mean_squared_error: 5.3728\n",
      "Epoch 30/30\n",
      "13215/13251 [============================>.] - ETA: 0s - loss: 1.4335 - accuracy: 0.3851 - mean_squared_error: 5.3719\n",
      "Epoch 30: val_loss did not improve from 1.40859\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4336 - accuracy: 0.3850 - mean_squared_error: 5.3713 - val_loss: 1.4149 - val_accuracy: 0.3831 - val_mean_squared_error: 5.3671\n",
      "Fold : 0  Test Loss: 1.4085912704467773  Test Accuracy: 0.39288192987442017  Test MSE: 5.368772029876709\n",
      "Epoch 1/30\n",
      "13242/13251 [============================>.] - ETA: 0s - loss: 1.4978 - accuracy: 0.3115 - mean_squared_error: 5.3655\n",
      "Epoch 1: val_loss improved from inf to 1.45877, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4978 - accuracy: 0.3115 - mean_squared_error: 5.3656 - val_loss: 1.4588 - val_accuracy: 0.3057 - val_mean_squared_error: 5.3650\n",
      "Epoch 2/30\n",
      "13230/13251 [============================>.] - ETA: 0s - loss: 1.4518 - accuracy: 0.3262 - mean_squared_error: 5.3662\n",
      "Epoch 2: val_loss improved from 1.45877 to 1.45481, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4517 - accuracy: 0.3262 - mean_squared_error: 5.3660 - val_loss: 1.4548 - val_accuracy: 0.3057 - val_mean_squared_error: 5.3680\n",
      "Epoch 3/30\n",
      "13236/13251 [============================>.] - ETA: 0s - loss: 1.4494 - accuracy: 0.3481 - mean_squared_error: 5.3666\n",
      "Epoch 3: val_loss improved from 1.45481 to 1.44395, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4494 - accuracy: 0.3481 - mean_squared_error: 5.3662 - val_loss: 1.4439 - val_accuracy: 0.4111 - val_mean_squared_error: 5.3660\n",
      "Epoch 4/30\n",
      "13249/13251 [============================>.] - ETA: 0s - loss: 1.4462 - accuracy: 0.3639 - mean_squared_error: 5.3664\n",
      "Epoch 4: val_loss improved from 1.44395 to 1.44132, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4462 - accuracy: 0.3639 - mean_squared_error: 5.3665 - val_loss: 1.4413 - val_accuracy: 0.4066 - val_mean_squared_error: 5.3656\n",
      "Epoch 5/30\n",
      "13226/13251 [============================>.] - ETA: 0s - loss: 1.4431 - accuracy: 0.3707 - mean_squared_error: 5.3662\n",
      "Epoch 5: val_loss improved from 1.44132 to 1.43819, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4431 - accuracy: 0.3706 - mean_squared_error: 5.3669 - val_loss: 1.4382 - val_accuracy: 0.3590 - val_mean_squared_error: 5.3670\n",
      "Epoch 6/30\n",
      "13247/13251 [============================>.] - ETA: 0s - loss: 1.4409 - accuracy: 0.3729 - mean_squared_error: 5.3674\n",
      "Epoch 6: val_loss improved from 1.43819 to 1.43240, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4409 - accuracy: 0.3730 - mean_squared_error: 5.3675 - val_loss: 1.4324 - val_accuracy: 0.3831 - val_mean_squared_error: 5.3663\n",
      "Epoch 7/30\n",
      "13226/13251 [============================>.] - ETA: 0s - loss: 1.4390 - accuracy: 0.3743 - mean_squared_error: 5.3680\n",
      "Epoch 7: val_loss did not improve from 1.43240\n",
      "13251/13251 [==============================] - 22s 2ms/step - loss: 1.4389 - accuracy: 0.3744 - mean_squared_error: 5.3681 - val_loss: 1.4747 - val_accuracy: 0.2618 - val_mean_squared_error: 5.3714\n",
      "Epoch 8/30\n",
      "13240/13251 [============================>.] - ETA: 0s - loss: 1.4378 - accuracy: 0.3749 - mean_squared_error: 5.3681\n",
      "Epoch 8: val_loss improved from 1.43240 to 1.43005, saving model to best_model.h5\n",
      "13251/13251 [==============================] - 23s 2ms/step - loss: 1.4378 - accuracy: 0.3749 - mean_squared_error: 5.3686 - val_loss: 1.4300 - val_accuracy: 0.3376 - val_mean_squared_error: 5.3669\n",
      "Epoch 9/30\n",
      " 2317/13251 [====>.........................] - ETA: 16s - loss: 1.4415 - accuracy: 0.3745 - mean_squared_error: 5.3654"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[198], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m history \u001b[38;5;241m=\u001b[39m History()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing lists\n",
    "crossentropyList = []\n",
    "accuracyList = []\n",
    "mseList = []\n",
    "\n",
    "accuracyhistoryList = []\n",
    "val_acchistoryList = []\n",
    "losshistoryList= []\n",
    "val_losshistoryList = []\n",
    "val_msehistoryList = []\n",
    "\n",
    "# KFold loop\n",
    "for i, (train, test) in enumerate(kfold.split(X,Y)):\n",
    "    \n",
    "    # Create model\n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Dense(23, activation=\"relu\", kernel_regularizer = regularizers.l2(0.9), input_dim=18)) #  Dense = fully connected\n",
    "    model.add(Dense(5, activation=\"softmax\", input_dim=23)) #  Softmax for crossentropy loss function\n",
    "\n",
    "    # Compile model\n",
    "    keras.optimizers.SGD(learning_rate=0.1, momentum=0.6) # Stochastic gradient descent optimizer\n",
    "    model.compile(optimizer = 'sgd', loss = 'sparse_categorical_crossentropy', metrics=['accuracy','mean_squared_error']) # Sparse categorical crossentropy loss for integer encoding \n",
    "\n",
    "    # Callback for EarlyStopping\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=0, patience=10) # When accuracy maximizes it waits another 10 epochs, it stops if there is no change. \n",
    "    #If there is, it continues until the next plateau or until it reaches the epochs intilized.\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)# Saves the model with the best performance obserbed during training\n",
    "    history = History()\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X[train], Y[train], validation_data =(X[test], Y[test]), batch_size= 10, epochs=30, verbose=1, callbacks= [es, mc, history]) # Validation with test dataset \n",
    "    \n",
    "    # Load best model\n",
    "    saved_model = load_model('best_model.h5')\n",
    "    \n",
    "    # Append trainig histories to lists\n",
    "    accuracyhistoryList.append(history.history['accuracy'])\n",
    "    val_acchistoryList.append(history.history['val_accuracy'])\n",
    "    losshistoryList.append(history.history['loss'])\n",
    "    val_losshistoryList.append(history.history['val_loss'])\n",
    "    val_msehistoryList.append(history.history['val_mean_squared_error'])\n",
    "    \n",
    "    # Evaluate model\n",
    "    scores = saved_model.evaluate(X[test], Y[test], verbose=0) # The \"best model\" is evaluated\n",
    "    crossentropyList.append(scores[0])\n",
    "    accuracyList.append(scores[1])\n",
    "    mseList.append(scores[2])\n",
    "    print(\"Fold :\", i, \" Test Loss:\", scores[0], \" Test Accuracy:\", scores[1], \" Test MSE:\", scores[2])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "70570ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History of \"average model\"\n",
    "avg_acc_hist =[]\n",
    "avg_val_acc_hist=[]\n",
    "avg_loss_hist =[]\n",
    "avg_val_loss_hist =[]\n",
    "avg_val_mse_history=[]\n",
    "avg_acc_hist=np.mean(accuracyhistoryList, axis=0)\n",
    "avg_val_acc_hist=np.mean(val_acchistoryList, axis=0)\n",
    "avg_loss_hist=np.mean(losshistoryList, axis=0)\n",
    "avg_val_loss_hist=np.mean(val_losshistoryList, axis=0)\n",
    "avg_val_mse_hist=np.mean(val_msehistoryList, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "245e0a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graphs for average model\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.plot(avg_acc_hist)\n",
    "plt.plot(avg_val_acc_hist)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(avg_loss_hist)\n",
    "plt.plot(avg_val_loss_hist)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for mse\n",
    "plt.plot(val_msehistoryList[i])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "17a4cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean values\n",
    "print(\"Mean Loss: \", np.mean(crossentropyList), \" Mean Accuracy:\", np.mean(accuracyList), \" Mean MSE:\", np.mean(mseList))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
